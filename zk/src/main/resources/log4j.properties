#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Set everything to be logged to the console
log4j.rootCategory= INFO, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Set the default spark-shell com.szkingdom.kdbi.job.common.log level to WARN. When running the spark-shell, the
# com.szkingdom.kdbi.job.common.log level for this class is used to overwrite the root logger's com.szkingdom.kdbi.job.common.log level, so that
# the user can have different defaults for the shell and regular Spark apps.
log4j.logger.org.apache.spark.repl.Main=WARN

# Settings to quiet third party logs that are too verbose
log4j.logger.org.spark_project.jetty=WARN
log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR

# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR


log4j.logger.analysisVisitLog=INFO,analysisVisitLog
log4j.appender.analysisVisitLog=org.apache.log4j.FileAppender
log4j.appender.analysisVisitLog.Encoding=UTF-8
#log4j.appender.analysisVisitLog.File=E://Users//Documents//kdbi-visit-analysis.log
log4j.appender.analysisVisitLog.File=/home/hadoop/logs/kdbi-visit-analysis.log
log4j.appender.analysisVisitLog.layout=org.apache.log4j.PatternLayout
log4j.appender.analysisVisitLog.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} [%p] [%t] %c.%M(%L) - %m%n
#log4j.additivity.analysisVisitLog=false

log4j.logger.analysisMonitorLog=INFO,analysisMonitorLog
log4j.appender.analysisMonitorLog=org.apache.log4j.FileAppender
log4j.appender.analysisMonitorLog.Encoding=UTF-8
#log4j.appender.analysisMonitorLog.File=E://Users//Documents//kdbi-monitor-analysis.log
log4j.appender.analysisMonitorLog.File=/home/hadoop/logs/kdbi-monitor-analysis.log
log4j.appender.analysisMonitorLog.layout=org.apache.log4j.PatternLayout
log4j.appender.analysisMonitorLog.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} [%p] [%t] %c.%M(%L) - %m%n
#log4j.additivity.analysisMonitorLog=false


###JDBCAppender
log4j.logger.analysisScheduleLog=INFO,analysisScheduleLog
log4j.appender.analysisScheduleLog = org.apache.log4j.jdbc.JDBCAppender
log4j.appender.analysisScheduleLog.BufferSize=1
#oracle
#log4j.appender.analysisScheduleLog.driver=oracle.jdbc.driver.OracleDriver
#log4j.appender.analysisScheduleLog.URL=jdbc:oracle:thin:@192.168.50.85:1521:ORCL
#log4j.appender.analysisScheduleLog.user=kdbase
#log4j.appender.analysisScheduleLog.password=kdbase
#log4j.appender.analysisScheduleLog.sql=INSERT INTO SPARK_SCHEDULE_LOG(APPLICATION_ID, LOG_LEVEL, METHOD, JOB_CODE,\
#  PRIORITY_SN, MSG, EXEC_TIME) VALUES('%X{applicationId}', '%p','%C.%M(%L)', \
#  '%X{jobCode}', '%X{prioritySn}', '%m', to_date('%d{yyyy-MM-dd HH:mm:ss}', 'yyyy-MM-dd HH24:mi:ss'))
##sqlserver
log4j.appender.analysisScheduleLog.driver=com.microsoft.sqlserver.jdbc.SQLServerDriver
log4j.appender.analysisScheduleLog.URL=jdbc:sqlserver://192.168.50.98:1433;DatabaseName=dcconfig_care_dev
log4j.appender.analysisScheduleLog.user=sa
log4j.appender.analysisScheduleLog.password=12345678

log4j.appender.analysisScheduleLog.sql=INSERT INTO SPARK_SCHEDULE_LOG(APPLICATION_ID, LOG_LEVEL, METHOD, JOB_CODE,\
  PRIORITY_SN, MSG, EXEC_TIME) VALUES('%X{applicationId}', '%p','%C.%M(%L)', \
  '%X{jobCode}', '%X{prioritySn}', '%m', '%d{yyyy-MM-dd HH:mm:ss}')
log4j.appender.analysisScheduleLog.layout=org.apache.log4j.PatternLayout
#log4j.additivity.analysisScheduleLog=false


log4j.logger.com.szkingdom.kdbi.job.core=DEBUG,console
log4j.additivity.com.szkingdom.kdbi.job.core=false

log4j.logger.com.szkingdom.kdbi.job.streaming.kafka=DEBUG,console
log4j.additivity.com.szkingdom.kdbi.job.streaming.kafka=false

log4j.logger.com.szkingdom.kdbi.job.transfer.engine=INFO,analysisScheduleLog
#log4j.additivity.com.szkingdom.kdbi.job.transfer.engine=false

log4j.logger.com.szkingdom.kdbi.job.governance.measure.engine=DEBUG,analysisScheduleLog
log4j.additivity.com.szkingdom.kdbi.job.governance.measure.engine=false